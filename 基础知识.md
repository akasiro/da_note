---
todo: 补充python绘图ROC和计算AUC代码
---


# ROC (receiver operating characteristic)
## 1 混淆矩阵（Confusion Matrix）
+ 定义：
	+ 预测结果：1=阳性；2=阴性
	+ ![[混淆矩阵.png]]
	+ $TP Rate = \frac{TP}{TP+FN}$ 真实为真时多大概率判定为真（召回率）
	+ $FP Rate = \frac{FP}{FP+TN}$ 真实为假时多大概率判定为真
## 2 ROC曲线定义
+ 横坐标轴 *FP Rate* (特异度)
+ 纵坐标轴 *TP Rate* (灵敏度)
+ 我们希望得到的ROC曲线是$TPRate > FPRate$。 因为当$TPRate = FPRate$ 时，代表不管真实值是什么都有相同的概率预测为阳性，相当于随机猜。
+ 
## 3 绘制ROC
将所有样本的预测得分从大到小排序，依次取预测得分作为threshold，计算出特异度和灵敏度，得到的点连线。
```python
from sklearn.metrics import plot_roc_curve

# 准备数据和模型
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
model = LogisticRegression()

# 拟合模型
model.fit(X_train, y_train)

# 绘制ROC曲线
plot_roc_curve(model, X_test, y_test)

# 显示图像
plt.show()

```

# AUC
## 1定义
+ 就是ROC曲线下方的面积，取值范围[0.5,1]，越大表示预测得越好
+ 一个正样本，一个负样本，模型预测的正样本的得分比负样本的得分还要大的可能性。
## 2计算

1：绘制ROC曲线，ROC曲线下面的面积就是AUC的值
2：假设总共有$m+n$个样本，其中正样本$m$个，负样本$n$个，总共有$m*n$个样本对，计数，正样本预测为正样本的概率值大于负样本预测为正样本的概率值记为1，累加计数，然后除以（$m*n$）就是AUC的值
+ 计算公式
	+ 所有样本按照预测得分倒序，并且得到每个样本的rank
	+ $AUC = \frac{\sum rank_{正样本}-\frac{M*(M+1)}{2}}{M*N}$
		+ $M$ 正样本的个数; $N$ 负样本个数
```python
from sklearn import metrics

auc = metrics.roc_auc_score(y_test, y_pred)
```

> [CSDN 机器学习auc曲线](https://blog.csdn.net/qq_16792139/article/details/115619410)
> [CSDN AUC，ROC我看到的最透彻的讲解](https://blog.csdn.net/u013385925/article/details/80385873)
> [CSDN AUC的计算方法](https://blog.csdn.net/qq_22238533/article/details/78666436)



# 召回率（recall）
## 定义：实际为真的有多少是被预测为正样本
## 公式
$recall = \frac{TP}{TP+TN}$
# 准确率（accuracy）
## 定义：整个数据集中有多少是被预测正确的
## 公式
$accuracy =  \frac{TP+FN}{total}$
# 精确率（precision）
## 定义：预测为正样本的样本中有多少是实际正样本
## 公式
$precision = \frac{TP}{TP+FP}$

```python
from sklearn.metrics import accuracy_score,precision_score,recall_score
accuracy = accuracy_score(y_true,y_pred)
precision = precision_score(y_true,y_pred)
recall = recall_score(y_true,y_pred)
```
# p值
P值（P value）就是**当原假设为真时，比所得到的样本观察结果更极端的结果出现的概率**。 如果P值很小，说明原假设情况的发生的概率很小，而如果出现了，根据小概率原理，我们就有理由拒绝原假设，P值越小，我们拒绝原假设的理由越充分。 总之，P值越小，表明结果越显著。